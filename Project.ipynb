{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to Data Science\n",
    "\n",
    "[Gina Sprint](https://ginasprint.com/)\n",
    "\n",
    "## Project (100 pts)\n",
    "\n",
    "## Learner Objectives\n",
    "At the conclusion of this programming assignment, participants should be able to:\n",
    "* Utilize the Pandas library to\n",
    "    * Load data from a CSV into a `DataFrame`\n",
    "    * Work with `DataFrame` and `Series`\n",
    "    * Join `DataFrame`s\n",
    "    * Save data to a CSV\n",
    "* Clean/prepare data\n",
    "* Use Matplotlib to visualize data\n",
    "* Write Markdown and code cells in Jupyter Notebook\n",
    "* Typeset equations using Latex\n",
    "* Tell a data science story\n",
    "* Utilize a kNN classifier, a decision tree classifier, and a random forest classifier from Sci-kit Learn\n",
    "* Evaluate models using train/test sets sampled using the hold out method and cross validation\n",
    "\n",
    "## Acknowledgments\n",
    "Content used in this assignment is based upon information in the following sources:\n",
    "* [The Spotify Hit Predictor Website](https://www.kaggle.com/datasets/theoverman/the-spotify-hit-predictor-dataset) from [Kaggle](https://www.kaggle.com/)\n",
    "* [Sci-kit Learn](https://scikit-learn.org/stable/index.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Github Repository Setup\n",
    "For the project, you will use GitHub to create a private code repository (add gsprint23 as a collaborator under your repo Settings) to submit your source/data files and to track code changes. To turn in your project, submit your your private Github repository's url into the Moodle project portal. \n",
    "\n",
    "Note: I highly recommend committing/pushing regularly so your work is always backed up."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Overview\n",
    "We are going to take a look at real dataset of songs from the 2010s decade (2010-2019). This dataset contains interesting insights about what makes a song a \"hit\" (e.g. mainstream successful) or a \"flop\" (e.g. not mainstream successful). For example, \"Shape of You\" by Ed Sheeran is a hit, while \"The Silence Thereafter\" by Craft is a flop (I haven't even heard of that song...). We are going to work with this data in the following ways:\n",
    "1. Part 1 Getting Started with Pandas\n",
    "    1. Load the data \n",
    "    1. Get familiar with the data\n",
    "1. Part 2 Cleaning and Exploratory Data Analysis (EDA)\n",
    "    1. Clean/prepare the data\n",
    "    1. Aggregate the data\n",
    "    1. Visualize the data\n",
    "1. Part 3 Data Storytelling with Jupyter Notebook\n",
    "1. Part 4 Machine Learning Classification\n",
    "    1. Prepare data for classification\n",
    "    1. Perform classification with three different classifiers\n",
    "     \n",
    "Dataset source: https://www.kaggle.com/datasets/theoverman/the-spotify-hit-predictor-dataset\n",
    "\n",
    "## Part 1 Getting Started with Pandas (20 pts)\n",
    "### Load the Data\n",
    "Download songs-of-10s.csv and genres-of-10s.csv from the files directory on Github: https://github.com/gsprint23/ZIME-Intro-to-Data-Science/tree/master/files. One way to download a file is to click \"Raw\" then right click on the page and click \"Save As.\" Move these files into the same folder as your local project Git repo. \n",
    "\n",
    "songs-of-10s.csv contains attributes of 6,000+ songs from the 2010s decade with detailed attributes about each song downloaded from the [Spotify Web API](https://developer.spotify.com/documentation/web-api/). Here is a sample of the format of the data in songs-of-10s.csv:\n",
    "\n",
    "|track|artist|uri|danceability|energy|key|...|target|\n",
    "|-|-|-|-|-|-|-|-|\n",
    "|Wild Things|Alessia Cara|`spotify:track:2ZyuwVvV6Z3XJaXIFbspeE`|0.741|0.626|1|...|1|\n",
    "|Surfboard|Esquivel!|`spotify:track:61APOtq25SCMuK0V5w2Kgp`|0.447|0.247|5|...|0|\n",
    "|...|...|...|...|...|...|...|...|\n",
    "\n",
    "Here is a description of each attribute in songs-of-10s.csv from the [dataset source](https://www.kaggle.com/datasets/theoverman/the-spotify-hit-predictor-dataset):\n",
    "- track: The Name of the track.\n",
    "- artist: The Name of the Artist.\n",
    "- uri: The resource identifier for the track.\n",
    "- danceability: Danceability describes how suitable a track is for dancing based on a combination of musical elements including tempo, rhythm stability, beat strength, and overall regularity. A value of 0.0 is least danceable and 1.0 is most danceable. \n",
    "- energy: Energy is a measure from 0.0 to 1.0 and represents a perceptual measure of intensity and activity. Typically, energetic tracks feel fast, loud, and noisy. For example, death metal has high energy, while a Bach prelude scores low on the scale. Perceptual features contributing to this attribute include dynamic range, perceived loudness, timbre, onset rate, and general entropy. \n",
    "- key: The estimated overall key of the track. Integers map to pitches using standard Pitch Class notation. E.g. 0 = C, 1 = C?/D?, 2 = D, and so on. If no key was detected, the value is -1.\n",
    "- loudness: The overall loudness of a track in decibels (dB). Loudness values are averaged across the entire track and are useful for comparing relative loudness of tracks. Loudness is the quality of a sound that is the primary psychological correlate of physical strength (amplitude). Values typical range between -60 and 0 db. \n",
    "- mode: Mode indicates the modality (major or minor) of a track, the type of scale from which its melodic content is derived. Major is represented by 1 and minor is 0.\n",
    "- speechiness: Speechiness detects the presence of spoken words in a track. The more exclusively speech-like the recording (e.g. talk show, audio book, poetry), the closer to 1.0 the attribute value. Values above 0.66 describe tracks that are probably made entirely of spoken words. Values between 0.33 and 0.66 describe tracks that may contain both music and speech, either in sections or layered, including such cases as rap music. Values below 0.33 most likely represent music and other non-speech-like tracks. \n",
    "- acousticness: A confidence measure from 0.0 to 1.0 of whether the track is acoustic. 1.0 represents high confidence the track is acoustic. The distribution of values for this feature look like this:\n",
    "- instrumentalness: Predicts whether a track contains no vocals. “Ooh” and “aah” sounds are treated as instrumental in this context. Rap or spoken word tracks are clearly “vocal”. The closer the instrumentalness value is to 1.0, the greater likelihood the track contains no vocal content. Values above 0.5 are intended to represent instrumental tracks, but confidence is higher as the value approaches 1.0. The distribution of values for this feature look like this:\n",
    "- liveness: Detects the presence of an audience in the recording. Higher liveness values represent an increased probability that the track was performed live. A value above 0.8 provides strong likelihood that the track is live.\n",
    "- valence: A measure from 0.0 to 1.0 describing the musical positiveness conveyed by a track. Tracks with high valence sound more positive (e.g. happy, cheerful, euphoric), while tracks with low valence sound more negative (e.g. sad, depressed, angry).\n",
    "- tempo: The overall estimated tempo of a track in beats per minute (BPM). In musical terminology, tempo is the speed or pace of a given piece and derives directly from the average beat duration. \n",
    "- duration_ms:  The duration of the track in milliseconds.\n",
    "- time_signature: An estimated overall time signature of a track. The time signature (meter) is a notational convention to specify how many beats are in each bar (or measure).\n",
    "- chorus_hit: This the the author's best estimate of when the chorus would start for the track. Its the timestamp of the start of the third section of the track. This feature was extracted from the data received by the API call for Audio Analysis of that particular track.\n",
    "- sections: The number of sections the particular track has. This feature was extracted from the data received by the API call for Audio Analysis of that particular track.\n",
    "- target: The target variable for the track. It can be either '0' or '1'. '1' implies that this song has featured in the weekly list (Issued by Billboards) of Hot-100 tracks in that decade at least once and is therefore a 'hit'. '0' Implies that the track is a 'flop'. The author's condition of a track being 'flop' is as follows:\n",
    "    - The track must not appear in the 'hit' list of that decade.\n",
    "    - The track's artist must not appear in the 'hit' list of that decade.\n",
    "    - The track must belong to a genre that could be considered non-mainstream and / or avant-garde. \n",
    "    - The track's genre must not have a song in the 'hit' list.\n",
    "    - The track must have 'US' as one of its markets.\n",
    "\n",
    "genres-of-10s.csv is a file I created for this assignment. It contains a list of genres for 3,000+ artists from the 2010s decade downloaded from the [Spotify Web API](https://developer.spotify.com/documentation/web-api/). Here is a sample of the format of the data in genres-of-10s.csv:\n",
    "\n",
    "|artist|genres|\n",
    "|-|-|\n",
    "|Witchtrap|\\['black thrash', 'metal colombiano'\\]|\n",
    "|Izïa|\\['french indie pop', 'french indietronica', 'french rock', 'nouvelle chanson francaise'\\]|\n",
    "|...|...|\n",
    "\n",
    "Note that artists typically are associated with multiple genres. We will need to figure out what to do with this later! :)\n",
    "\n",
    "Write code to perform the following:\n",
    "1. Read each csv file into a Pandas `DataFrame` object. The header row is the first row in each of the files.\n",
    "1. Decide what index to use for each of the `DataFrame`s\n",
    "1. Print out the first few rows of each `DataFrame` to confirm your index and your columns are setup properly\n",
    "1. Outer join the two `DataFrame`s appropriately to make one `DataFrame`\n",
    "\n",
    "### Get Familiar with the Data\n",
    "Write code to answer the following questions for your joined `DataFrame`:\n",
    "1. How many instances are there?\n",
    "1. How many attributes are there? Which ones are categorical? Which ones are numeric?\n",
    "1. Are there any missing values? If so how many and in which column(s)?\n",
    "1. How many hits are there and how many flops are there?\n",
    "1. What are the top 5 artists with the most songs in the dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 Cleaning and Exploratory Data Analysis (30 pts)\n",
    "Will post later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3 Data Storytelling with Jupyter Notebook (20 pts)\n",
    "Will post later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Part 4 Machine Learning Classification (30 pts)\n",
    "Will post later\n",
    "\n",
    "### BONUS (5 pts)\n",
    "Will post later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submitting Assignments\n",
    "1. Submit your assignment via a private Github repo. See the \"Github Repository Setup\" section at the beginning of this document for details on how to do this. You must commit your solution by the due date and time.\n",
    "1. Your repo should contain only your HitFlop.ipynb file, your utils.py file, your input/output.csv files, and your charts/ directory. Double check that this is the case by cloning (or downloading a zip) your submission repo and running your code like we will when we grade your code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grading Guidelines\n",
    "This assignment is worth 100 points + 5 points bonus. Your assignment will be evaluated based on a successful execution (using the Anaconda Python Distribution v3.9) and adherence to the program requirements. We will grade according to the following criteria:\n",
    "* 20 pts for correct part 1\n",
    "    * 10 pts for loading the data\n",
    "    * 10 pts for getting familiar with the data\n",
    "* 30 pts for correct part 2\n",
    "    * 10 pts for cleaning\n",
    "    * 5 pts for aggregating\n",
    "    * 5 pts for genre chart and hits/flops pie chart\n",
    "    * 5 pts for histograms\n",
    "    * 5 pts for boxplots\n",
    "* 30 pts for correct part 4\n",
    "    * 5 pts for setup of X, y\n",
    "    * 5 pts for 3 classifiers setup\n",
    "    * 5 pts for encoding and scaling\n",
    "    * 5 pts for hold out method\n",
    "    * 5 pts for cross validation\n",
    "    * 5 pts for tuning parameters to improve classification\n",
    "* 20 pts for general data storytelling with Jupyter Notebook and adherence to course [coding standard](https://nbviewer.jupyter.org/github/GonzagaCPSC222/DAs/blob/master/Coding%20Standard.ipynb)\n",
    "    * 5 pts for organization and section headers\n",
    "    * 5 pts for short code cells with appropriate input/output (including charts)\n",
    "    * 5 pts for clear narrative and formulas\n",
    "    * 5 pts for clean and documented utils.py"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
